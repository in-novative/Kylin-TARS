#!/usr/bin/env python3
"""
è®°å¿†æ¨¡å— - åä½œè½¨è¿¹å­˜å‚¨ä¸æ£€ç´¢

æœ¬æ¨¡å—å®ç° GUI Agent çš„è®°å¿†åŠŸèƒ½ï¼š
1. å­˜å‚¨åä½œè½¨è¿¹ï¼ˆä»»åŠ¡ + æ¨ç†é“¾ + æ‰§è¡Œç»“æœ + æˆªå›¾è·¯å¾„ï¼‰
2. æŒ‰æ—¶é—´/å…³é”®è¯æ£€ç´¢å†å²è½¨è¿¹
3. æ”¯æŒç›¸ä¼¼ä»»åŠ¡çš„æ¨ç†é“¾å¤ç”¨

ä½œè€…ï¼šGUI Agent Team
æ—¥æœŸï¼š2024-12
"""

import json
import os
import time
import hashlib
from datetime import datetime
from pathlib import Path
from typing import Optional, Dict, List, Any

# ============================================================
# å­˜å‚¨é…ç½®
# ============================================================

# å­˜å‚¨æ¨¡å¼é…ç½®
# - "project": å­˜å‚¨åœ¨é¡¹ç›®ç›®å½•å†…ï¼ˆä¾¿äºç‰ˆæœ¬æ§åˆ¶å’Œé¡¹ç›®è¿ç§»ï¼‰
# - "system": å­˜å‚¨åœ¨ç”¨æˆ·é…ç½®ç›®å½•ï¼ˆæ•°æ®æŒä¹…åŒ–ï¼Œå¤šé¡¹ç›®å…±äº«ï¼‰
STORAGE_MODE = os.environ.get("MEMORY_STORAGE_MODE", "project")  # é»˜è®¤æ”¹ä¸ºé¡¹ç›®å†…

# é¡¹ç›®æ ¹ç›®å½•ï¼ˆè‡ªåŠ¨æ£€æµ‹å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•ï¼‰
PROJECT_ROOT = Path(__file__).parent.absolute()

# æ ¹æ®æ¨¡å¼é€‰æ‹©å­˜å‚¨ç›®å½•
if STORAGE_MODE == "project":
    # å­˜å‚¨åœ¨é¡¹ç›®å†…çš„ data/memory ç›®å½•
    STORAGE_DIR = str(PROJECT_ROOT / "data" / "collaboration_memory")
else:
    # å­˜å‚¨åœ¨ç”¨æˆ·é…ç½®ç›®å½•ï¼ˆXDGè§„èŒƒï¼‰
    STORAGE_DIR = os.path.expanduser("~/.config/kylin-gui-agent/collaboration_memory")

# ç¡®ä¿å­˜å‚¨ç›®å½•å­˜åœ¨
os.makedirs(STORAGE_DIR, exist_ok=True)

# æ‰“å°å½“å‰å­˜å‚¨ä½ç½®ï¼ˆä»…é¦–æ¬¡å¯¼å…¥æ—¶ï¼‰
print(f"ğŸ“ è®°å¿†å­˜å‚¨ä½ç½®: {STORAGE_DIR}")


# ============================================================
# è¾…åŠ©å‡½æ•°
# ============================================================

def generate_task_hash(task: str) -> str:
    """
    ç”Ÿæˆä»»åŠ¡å”¯ä¸€æ ‡è¯†ï¼ˆMD5å“ˆå¸Œå‰8ä½ï¼‰
    
    Args:
        task: ç”¨æˆ·ä»»åŠ¡æè¿°
        
    Returns:
        8ä½å“ˆå¸Œå­—ç¬¦ä¸²
    """
    return hashlib.md5(task.encode('utf-8')).hexdigest()[:8]


def validate_screenshot_paths(paths: List[str]) -> List[str]:
    """
    éªŒè¯æˆªå›¾è·¯å¾„ï¼Œåªä¿ç•™å­˜åœ¨çš„æ–‡ä»¶
    
    Args:
        paths: æˆªå›¾è·¯å¾„åˆ—è¡¨
        
    Returns:
        æœ‰æ•ˆçš„æˆªå›¾è·¯å¾„åˆ—è¡¨
    """
    if not paths:
        return []
    return [p for p in paths if os.path.exists(p)]


# ============================================================
# æ ¸å¿ƒå­˜å‚¨å‡½æ•°
# ============================================================

def save_collaboration_trajectory(
    task: str,
    reasoning_chain: Any,
    execution_result: str = "",
    screenshot_paths: Optional[List[str]] = None,
    gui_action: Optional[Dict] = None,
    success: bool = True,
    metadata: Optional[Dict] = None
) -> str:
    """
    ä¿å­˜åä½œè½¨è¿¹åˆ°æœ¬åœ°JSONæ–‡ä»¶
    
    Args:
        task: ç”¨æˆ·åŸå§‹ä»»åŠ¡
        reasoning_chain: System-2ç”Ÿæˆçš„æ¨ç†é“¾ï¼ˆå­—å…¸æˆ–JSONå­—ç¬¦ä¸²ï¼‰
        execution_result: å­æ™ºèƒ½ä½“æ‰§è¡Œç»“æœæè¿°
        screenshot_paths: æ‰§è¡Œè¿‡ç¨‹çš„æˆªå›¾è·¯å¾„åˆ—è¡¨
        gui_action: GUIæ“ä½œè®°å½•
        success: æ‰§è¡Œæ˜¯å¦æˆåŠŸ
        metadata: é¢å¤–å…ƒæ•°æ®
        
    Returns:
        ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
    """
    # å¤„ç†æ¨ç†é“¾æ ¼å¼
    if isinstance(reasoning_chain, str):
        try:
            reasoning_chain = json.loads(reasoning_chain)
        except json.JSONDecodeError:
            reasoning_chain = {"raw": reasoning_chain}
    
    # éªŒè¯æˆªå›¾è·¯å¾„
    valid_screenshots = validate_screenshot_paths(screenshot_paths or [])
    
    # æå–å…³é”®ä¿¡æ¯ç”¨äºæ£€ç´¢
    keywords = extract_keywords(task)
    agents_involved = extract_agents(reasoning_chain)
    
    # æ„å»ºè½¨è¿¹æ•°æ®ç»“æ„
    trajectory = {
        # åŸºæœ¬ä¿¡æ¯
        "task": task,
        "task_hash": generate_task_hash(task),
        "keywords": keywords,
        
        # æ¨ç†é“¾
        "reasoning_chain": reasoning_chain,
        
        # æ‰§è¡Œä¿¡æ¯
        "execution_result": execution_result,
        "gui_action": gui_action,
        "agents_involved": agents_involved,
        "success": success,
        
        # æˆªå›¾
        "screenshot_paths": valid_screenshots,
        "screenshot_count": len(valid_screenshots),
        
        # æ—¶é—´æˆ³
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "timestamp_unix": int(time.time()),
        
        # å…ƒæ•°æ®
        "metadata": metadata or {}
    }
    
    # ç”Ÿæˆæ–‡ä»¶åï¼ˆæ—¶é—´æˆ³_ä»»åŠ¡å“ˆå¸Œ.jsonï¼‰
    filename = f"{trajectory['timestamp_unix']}_{trajectory['task_hash']}.json"
    file_path = os.path.join(STORAGE_DIR, filename)
    
    # ä¿å­˜åˆ°JSONæ–‡ä»¶
    with open(file_path, "w", encoding="utf-8") as f:
        json.dump(trajectory, f, ensure_ascii=False, indent=2)
    
    print(f"âœ“ åä½œè½¨è¿¹å·²ä¿å­˜: {file_path}")
    return file_path


def extract_keywords(task: str) -> List[str]:
    """
    ä»ä»»åŠ¡æè¿°ä¸­æå–å…³é”®è¯
    
    Args:
        task: ç”¨æˆ·ä»»åŠ¡æè¿°
        
    Returns:
        å…³é”®è¯åˆ—è¡¨
    """
    # å¸¸è§æ“ä½œå…³é”®è¯
    action_keywords = [
        "æœç´¢", "æŸ¥æ‰¾", "è®¾ç½®", "æ›´æ¢", "è°ƒæ•´", "ç§»åŠ¨", "åˆ é™¤", "å¤åˆ¶",
        "æ‰“å¼€", "å…³é—­", "å®‰è£…", "å¸è½½", "ä¸‹è½½", "ä¸Šä¼ ", "åˆ›å»º", "ä¿®æ”¹"
    ]
    
    # å¸¸è§å¯¹è±¡å…³é”®è¯
    object_keywords = [
        "æ–‡ä»¶", "ç›®å½•", "æ–‡ä»¶å¤¹", "å£çº¸", "éŸ³é‡", "äº®åº¦", "ç½‘ç»œ", "è“ç‰™",
        "æµè§ˆå™¨", "ç»ˆç«¯", "åº”ç”¨", "ç¨‹åº", "å›¾ç‰‡", "æ–‡æ¡£", "è§†é¢‘", "éŸ³ä¹"
    ]
    
    keywords = []
    
    # æå–æ“ä½œå…³é”®è¯
    for kw in action_keywords:
        if kw in task:
            keywords.append(kw)
    
    # æå–å¯¹è±¡å…³é”®è¯
    for kw in object_keywords:
        if kw in task:
            keywords.append(kw)
    
    # æå–è·¯å¾„ï¼ˆå¦‚ ~/Downloadsï¼‰
    import re
    paths = re.findall(r'[~/\w]+/\w+', task)
    keywords.extend(paths)
    
    # æå–æ–‡ä»¶æ‰©å±•åï¼ˆå¦‚ .png, .tmpï¼‰
    extensions = re.findall(r'\.\w+', task)
    keywords.extend(extensions)
    
    return list(set(keywords))  # å»é‡


def extract_agents(reasoning_chain: Dict) -> List[str]:
    """
    ä»æ¨ç†é“¾ä¸­æå–æ¶‰åŠçš„æ™ºèƒ½ä½“
    
    Args:
        reasoning_chain: æ¨ç†é“¾å­—å…¸
        
    Returns:
        æ™ºèƒ½ä½“åç§°åˆ—è¡¨
    """
    agents = set()
    
    # ä» thought_chain.agent_selection æå–
    if "thought_chain" in reasoning_chain:
        tc = reasoning_chain["thought_chain"]
        if "agent_selection" in tc:
            for item in tc["agent_selection"]:
                if isinstance(item, dict) and "agent" in item:
                    agents.add(item["agent"])
    
    # ä» execution_plan æå–
    if "execution_plan" in reasoning_chain:
        for step in reasoning_chain["execution_plan"]:
            if isinstance(step, dict) and "agent" in step:
                agents.add(step["agent"])
    
    return list(agents)


# ============================================================
# æ£€ç´¢å‡½æ•°
# ============================================================

def list_trajectories(limit: int = 10, success_only: bool = False) -> List[Dict]:
    """
    åˆ—å‡ºæœ€è¿‘çš„åä½œè½¨è¿¹ï¼ˆæŒ‰æ—¶é—´å€’åºï¼‰
    
    Args:
        limit: è¿”å›æ¡æ•°
        success_only: æ˜¯å¦åªè¿”å›æˆåŠŸçš„è½¨è¿¹
        
    Returns:
        è½¨è¿¹åˆ—è¡¨
    """
    # è·å–æ‰€æœ‰è½¨è¿¹æ–‡ä»¶
    trajectory_files = [f for f in os.listdir(STORAGE_DIR) if f.endswith(".json")]
    
    # æŒ‰æ—¶é—´æˆ³å€’åºæ’åº
    trajectory_files.sort(reverse=True, key=lambda x: int(x.split("_")[0]))
    
    # è¯»å–è½¨è¿¹
    trajectories = []
    for file in trajectory_files:
        if len(trajectories) >= limit:
            break
            
        file_path = os.path.join(STORAGE_DIR, file)
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                traj = json.load(f)
                if success_only and not traj.get("success", False):
                    continue
                trajectories.append(traj)
        except Exception as e:
            print(f"è¯»å–è½¨è¿¹å¤±è´¥ {file}: {e}")
    
    return trajectories


def search_trajectories(
    keyword: str = None,
    agent: str = None,
    limit: int = 10
) -> List[Dict]:
    """
    æœç´¢åä½œè½¨è¿¹
    
    Args:
        keyword: å…³é”®è¯ï¼ˆåŒ¹é…ä»»åŠ¡æè¿°æˆ–å…³é”®è¯åˆ—è¡¨ï¼‰
        agent: æ™ºèƒ½ä½“åç§°ï¼ˆåŒ¹é…æ¶‰åŠçš„æ™ºèƒ½ä½“ï¼‰
        limit: è¿”å›æ¡æ•°
        
    Returns:
        åŒ¹é…çš„è½¨è¿¹åˆ—è¡¨
    """
    all_trajectories = list_trajectories(limit=1000)  # è·å–æ‰€æœ‰è½¨è¿¹
    
    matched = []
    for traj in all_trajectories:
        if len(matched) >= limit:
            break
        
        # å…³é”®è¯åŒ¹é…
        if keyword:
            task_match = keyword.lower() in traj.get("task", "").lower()
            keywords_match = keyword.lower() in " ".join(traj.get("keywords", [])).lower()
            if not (task_match or keywords_match):
                continue
        
        # æ™ºèƒ½ä½“åŒ¹é…
        if agent:
            if agent not in traj.get("agents_involved", []):
                continue
        
        matched.append(traj)
    
    return matched


def find_similar_task(task: str, threshold: float = 0.5) -> Optional[Dict]:
    """
    æŸ¥æ‰¾ç›¸ä¼¼ä»»åŠ¡çš„å†å²è½¨è¿¹ï¼ˆç”¨äºæ¨ç†é“¾å¤ç”¨ï¼‰
    
    Args:
        task: å½“å‰ä»»åŠ¡æè¿°
        threshold: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆ0-1ï¼‰
        
    Returns:
        æœ€ç›¸ä¼¼çš„è½¨è¿¹ï¼Œæ— åŒ¹é…è¿”å›None
    """
    current_keywords = set(extract_keywords(task))
    if not current_keywords:
        return None
    
    all_trajectories = list_trajectories(limit=100, success_only=True)
    
    best_match = None
    best_score = 0
    
    for traj in all_trajectories:
        traj_keywords = set(traj.get("keywords", []))
        if not traj_keywords:
            continue
        
        # è®¡ç®—Jaccardç›¸ä¼¼åº¦
        intersection = len(current_keywords & traj_keywords)
        union = len(current_keywords | traj_keywords)
        similarity = intersection / union if union > 0 else 0
        
        if similarity > best_score and similarity >= threshold:
            best_score = similarity
            best_match = traj
    
    if best_match:
        print(f"âœ“ æ‰¾åˆ°ç›¸ä¼¼ä»»åŠ¡ (ç›¸ä¼¼åº¦: {best_score:.2f}): {best_match['task'][:50]}...")
    
    return best_match


def get_trajectory_by_hash(task_hash: str) -> Optional[Dict]:
    """
    æ ¹æ®ä»»åŠ¡å“ˆå¸Œè·å–è½¨è¿¹
    
    Args:
        task_hash: ä»»åŠ¡å“ˆå¸Œå€¼
        
    Returns:
        è½¨è¿¹å­—å…¸
    """
    trajectory_files = [f for f in os.listdir(STORAGE_DIR) if f.endswith(".json")]
    
    for file in trajectory_files:
        if task_hash in file:
            file_path = os.path.join(STORAGE_DIR, file)
            with open(file_path, "r", encoding="utf-8") as f:
                return json.load(f)
    
    return None


# ============================================================
# ç»Ÿè®¡å‡½æ•°
# ============================================================

def get_memory_stats() -> Dict:
    """
    è·å–è®°å¿†æ¨¡å—ç»Ÿè®¡ä¿¡æ¯
    
    Returns:
        ç»Ÿè®¡ä¿¡æ¯å­—å…¸
    """
    trajectory_files = [f for f in os.listdir(STORAGE_DIR) if f.endswith(".json")]
    
    total_count = len(trajectory_files)
    success_count = 0
    agent_counts = {}
    
    for file in trajectory_files:
        file_path = os.path.join(STORAGE_DIR, file)
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                traj = json.load(f)
                if traj.get("success", False):
                    success_count += 1
                for agent in traj.get("agents_involved", []):
                    agent_counts[agent] = agent_counts.get(agent, 0) + 1
        except:
            pass
    
    return {
        "total_trajectories": total_count,
        "success_count": success_count,
        "success_rate": success_count / total_count if total_count > 0 else 0,
        "agent_usage": agent_counts,
        "storage_dir": STORAGE_DIR
    }


def clear_old_trajectories(days: int = 30) -> int:
    """
    æ¸…ç†æŒ‡å®šå¤©æ•°ä¹‹å‰çš„è½¨è¿¹
    
    Args:
        days: ä¿ç•™æœ€è¿‘Nå¤©çš„è½¨è¿¹
        
    Returns:
        åˆ é™¤çš„æ–‡ä»¶æ•°é‡
    """
    cutoff_time = int(time.time()) - (days * 24 * 60 * 60)
    trajectory_files = [f for f in os.listdir(STORAGE_DIR) if f.endswith(".json")]
    
    deleted_count = 0
    for file in trajectory_files:
        try:
            timestamp = int(file.split("_")[0])
            if timestamp < cutoff_time:
                os.remove(os.path.join(STORAGE_DIR, file))
                deleted_count += 1
        except:
            pass
    
    if deleted_count > 0:
        print(f"å·²æ¸…ç† {deleted_count} æ¡è¿‡æœŸè½¨è¿¹")
    
    return deleted_count


# ============================================================
# ä¸ System-2 é›†æˆ
# ============================================================

def save_from_reasoning_result(result: Dict, execution_result: str = "") -> str:
    """
    ä» system2_prompt.py çš„ execute_reasoning_pipeline ç»“æœä¿å­˜è½¨è¿¹
    
    Args:
        result: execute_reasoning_pipeline çš„è¿”å›å€¼
        execution_result: æ‰§è¡Œç»“æœæè¿°
        
    Returns:
        ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
    """
    return save_collaboration_trajectory(
        task=result.get("user_task", ""),
        reasoning_chain=result.get("master_reasoning", {}),
        execution_result=execution_result,
        screenshot_paths=[result.get("screenshot")] if result.get("screenshot") else [],
        gui_action=result.get("gui_action"),
        success=result.get("success", False),
        metadata={
            "source": "system2_prompt",
            "original_timestamp": result.get("timestamp")
        }
    )


# ============================================================
# æµ‹è¯•å‡½æ•°
# ============================================================

def test_memory_store():
    """æµ‹è¯•è®°å¿†å­˜å‚¨åŠŸèƒ½"""
    print("=" * 60)
    print("è®°å¿†æ¨¡å—æµ‹è¯•")
    print("=" * 60)
    
    # æµ‹è¯•æ•°æ®
    test_cases = [
        {
            "task": "æœç´¢~/Downloadsç›®å½•çš„pngæ–‡ä»¶å¹¶è®¾ç½®ä¸ºå£çº¸",
            "reasoning_chain": {
                "thought_chain": {
                    "task_understanding": "ç”¨æˆ·å¸Œæœ›ä»ä¸‹è½½ç›®å½•æ‰¾åˆ°PNGå›¾ç‰‡å¹¶è®¾ç½®ä¸ºæ¡Œé¢å£çº¸",
                    "task_decomposition": "1. æœç´¢~/Downloadsç›®å½•ä¸‹çš„pngæ–‡ä»¶ï¼›2. é€‰æ‹©å›¾ç‰‡ï¼›3. è®¾ç½®å£çº¸",
                    "agent_selection": [
                        {"step": 1, "agent": "FileAgent", "reason": "éœ€è¦æ–‡ä»¶æœç´¢åŠŸèƒ½"},
                        {"step": 2, "agent": "SettingsAgent", "reason": "éœ€è¦ç³»ç»Ÿè®¾ç½®åŠŸèƒ½"}
                    ],
                    "risk_assessment": "~/Downloadsç›®å½•å¯èƒ½æ²¡æœ‰pngæ–‡ä»¶",
                    "fallback_plan": "å¦‚æœæ²¡æœ‰pngæ–‡ä»¶ï¼Œæç¤ºç”¨æˆ·ä¸Šä¼ å›¾ç‰‡"
                },
                "execution_plan": [
                    {"step": 1, "action": "æœç´¢pngæ–‡ä»¶", "agent": "FileAgent"},
                    {"step": 2, "action": "è®¾ç½®å£çº¸", "agent": "SettingsAgent"}
                ],
                "milestone_markers": ["search_complete", "wallpaper_set"]
            },
            "execution_result": "æˆåŠŸæœç´¢åˆ°2ä¸ªpngæ–‡ä»¶ï¼Œå£çº¸è®¾ç½®å®Œæˆ",
            "success": True
        },
        {
            "task": "æŠŠç³»ç»ŸéŸ³é‡è°ƒåˆ°50%",
            "reasoning_chain": {
                "thought_chain": {
                    "task_understanding": "ç”¨æˆ·å¸Œæœ›å°†ç³»ç»ŸéŸ³é‡è°ƒæ•´åˆ°50%",
                    "task_decomposition": "1. æ‰“å¼€ç³»ç»Ÿè®¾ç½®ï¼›2. è°ƒæ•´éŸ³é‡",
                    "agent_selection": [
                        {"step": 1, "agent": "SettingsAgent", "reason": "éœ€è¦ç³»ç»Ÿè®¾ç½®åŠŸèƒ½"}
                    ],
                    "risk_assessment": "å¯èƒ½æ‰¾ä¸åˆ°éŸ³é‡æ§åˆ¶é€‰é¡¹",
                    "fallback_plan": "ä½¿ç”¨ç»ˆç«¯å‘½ä»¤è°ƒæ•´éŸ³é‡"
                },
                "execution_plan": [
                    {"step": 1, "action": "æ‰“å¼€ç³»ç»Ÿè®¾ç½®", "agent": "SettingsAgent"},
                    {"step": 2, "action": "è°ƒæ•´éŸ³é‡åˆ°50%", "agent": "SettingsAgent"}
                ],
                "milestone_markers": ["settings_opened", "volume_set"]
            },
            "execution_result": "éŸ³é‡å·²è°ƒæ•´åˆ°50%",
            "success": True
        },
        {
            "task": "å°†ä¸‹è½½ç›®å½•çš„tmpæ–‡ä»¶ç§»åŠ¨åˆ°å›æ”¶ç«™",
            "reasoning_chain": {
                "thought_chain": {
                    "task_understanding": "ç”¨æˆ·éœ€è¦åˆ é™¤tmpæ–‡ä»¶",
                    "task_decomposition": "1. æœç´¢tmpæ–‡ä»¶ï¼›2. ç§»åŠ¨åˆ°å›æ”¶ç«™",
                    "agent_selection": [
                        {"step": 1, "agent": "FileAgent", "reason": "éœ€è¦æ–‡ä»¶æ“ä½œåŠŸèƒ½"}
                    ],
                    "risk_assessment": "æ–‡ä»¶å¯èƒ½ä¸å­˜åœ¨",
                    "fallback_plan": "æç¤ºç”¨æˆ·æ£€æŸ¥æ–‡ä»¶å"
                },
                "execution_plan": [
                    {"step": 1, "action": "æœç´¢tmpæ–‡ä»¶", "agent": "FileAgent"},
                    {"step": 2, "action": "ç§»åŠ¨åˆ°å›æ”¶ç«™", "agent": "FileAgent"}
                ],
                "milestone_markers": ["search_complete", "file_moved"]
            },
            "execution_result": "æ–‡ä»¶å·²ç§»åŠ¨åˆ°å›æ”¶ç«™",
            "success": True
        }
    ]
    
    # ä¿å­˜æµ‹è¯•è½¨è¿¹
    print("\n--- ä¿å­˜æµ‹è¯•è½¨è¿¹ ---")
    saved_paths = []
    for i, case in enumerate(test_cases, 1):
        print(f"\næµ‹è¯• {i}: {case['task'][:40]}...")
        path = save_collaboration_trajectory(
            task=case["task"],
            reasoning_chain=case["reasoning_chain"],
            execution_result=case["execution_result"],
            success=case["success"]
        )
        saved_paths.append(path)
        time.sleep(1)  # ç¡®ä¿æ—¶é—´æˆ³ä¸åŒ
    
    # æµ‹è¯•åˆ—è¡¨åŠŸèƒ½
    print("\n--- åˆ—å‡ºæœ€è¿‘è½¨è¿¹ ---")
    recent = list_trajectories(limit=3)
    for traj in recent:
        print(f"  â€¢ {traj['task'][:40]}... [{traj['timestamp']}]")
    
    # æµ‹è¯•æœç´¢åŠŸèƒ½
    print("\n--- å…³é”®è¯æœç´¢æµ‹è¯• ---")
    results = search_trajectories(keyword="å£çº¸", limit=5)
    print(f"æœç´¢ 'å£çº¸': æ‰¾åˆ° {len(results)} æ¡è®°å½•")
    for r in results:
        print(f"  â€¢ {r['task'][:50]}...")
    
    # æµ‹è¯•æ™ºèƒ½ä½“æœç´¢
    print("\n--- æ™ºèƒ½ä½“æœç´¢æµ‹è¯• ---")
    results = search_trajectories(agent="FileAgent", limit=5)
    print(f"æœç´¢ FileAgent: æ‰¾åˆ° {len(results)} æ¡è®°å½•")
    
    # æµ‹è¯•ç›¸ä¼¼ä»»åŠ¡æŸ¥æ‰¾
    print("\n--- ç›¸ä¼¼ä»»åŠ¡æŸ¥æ‰¾æµ‹è¯• ---")
    similar = find_similar_task("æœç´¢ä¸‹è½½ç›®å½•çš„jpgæ–‡ä»¶å¹¶è®¾ç½®ä¸ºå£çº¸")
    if similar:
        print(f"  åŒ¹é…ä»»åŠ¡: {similar['task'][:50]}...")
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    print("\n--- è®°å¿†ç»Ÿè®¡ ---")
    stats = get_memory_stats()
    print(f"  æ€»è½¨è¿¹æ•°: {stats['total_trajectories']}")
    print(f"  æˆåŠŸæ•°é‡: {stats['success_count']}")
    print(f"  æˆåŠŸç‡: {stats['success_rate']:.1%}")
    print(f"  æ™ºèƒ½ä½“ä½¿ç”¨: {stats['agent_usage']}")
    print(f"  å­˜å‚¨ç›®å½•: {stats['storage_dir']}")
    
    print("\n" + "=" * 60)
    print("âœ“ è®°å¿†æ¨¡å—æµ‹è¯•å®Œæˆï¼")
    print("=" * 60)


if __name__ == "__main__":
    test_memory_store()

