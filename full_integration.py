#!/usr/bin/env python3
"""
å…¨é“¾è·¯è”è°ƒè„šæœ¬ - Kylin-TARS GUI Agent

æœ¬è„šæœ¬ç”¨äºè”è°ƒ System-2 æ¨ç†ã€MCP åè®®ã€å­æ™ºèƒ½ä½“ã€è®°å¿†æ¨¡å—çš„å®Œæ•´æµç¨‹ã€‚

ä½¿ç”¨æ–¹å¼ï¼š
1. æ¨¡æ‹Ÿæ¨¡å¼ï¼ˆæ— éœ€å¯åŠ¨ MCP Serverï¼‰ï¼š
   python full_integration.py

2. çœŸå®æ¨¡å¼ï¼ˆéœ€è¦å…ˆå¯åŠ¨ MCP Server å’Œå­æ™ºèƒ½ä½“ï¼‰ï¼š
   python full_integration.py --real

ä½œè€…ï¼šGUI Agent Team
æ—¥æœŸï¼š2024-12
"""

import os
import sys
import json
import time
import argparse
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple

# æ·»åŠ é¡¹ç›®è·¯å¾„
PROJECT_ROOT = Path(__file__).parent
sys.path.insert(0, str(PROJECT_ROOT))

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from system2_memory import (
    reasoning_with_memory,
    get_reasoning_for_master,
    validate_for_mcp,
    normalize_for_mcp
)
from memory_store import (
    save_collaboration_trajectory,
    list_trajectories,
    STORAGE_DIR
)
from memory_retrieve import (
    retrieve_similar_trajectory,
    reuse_reasoning_chain,
    reasoning_with_retrieval
)

# ============================================================
# é…ç½®å¸¸é‡
# ============================================================

# MCP é…ç½®ï¼ˆæˆå‘˜Aï¼‰
MCP_CONFIG_A = {
    "service_name": "com.kylin.ai.mcp.MasterAgent",
    "object_path": "/com/kylin/ai/mcp/MasterAgent",
    "interface_name": "com.kylin.ai.mcp.MasterAgent"
}

# MCP é…ç½®ï¼ˆæˆå‘˜Cï¼‰
MCP_CONFIG_C = {
    "service_name": "com.mcp.server",
    "object_path": "/com/mcp/server",
    "interface_name": "com.mcp.server.Interface"
}

# å­æ™ºèƒ½ä½“é…ç½®
AGENTS_CONFIG = {
    "FileAgent": {
        "service": "com.mcp.agent.file",
        "path": "/com/mcp/agent/file",
        "interface": "com.mcp.agent.file.Interface",
        "tools": [
            {
                "name": "file_agent.search_file",
                "description": "æŒ‰å…³é”®è¯é€’å½’/éé€’å½’æœç´¢æŒ‡å®šç›®å½•ä¸‹çš„æ–‡ä»¶",
                "parameters": {
                    "search_path": "string",
                    "keyword": "string",
                    "recursive": "boolean"
                }
            },
            {
                "name": "file_agent.move_to_trash",
                "description": "å°†æŒ‡å®šæ–‡ä»¶/ç›®å½•ç§»åŠ¨åˆ°å›æ”¶ç«™",
                "parameters": {
                    "file_path": "string"
                }
            }
        ]
    },
    "SettingsAgent": {
        "service": "com.mcp.agent.settings",
        "path": "/com/mcp/agent/settings",
        "interface": "com.mcp.agent.settings.Interface",
        "tools": [
            {
                "name": "settings_agent.change_wallpaper",
                "description": "è°ƒç”¨DBuså®ç°å£çº¸ä¿®æ”¹",
                "parameters": {
                    "wallpaper_path": "string",
                    "scale": "string"
                }
            },
            {
                "name": "settings_agent.adjust_volume",
                "description": "è°ƒç”¨gsettingså®ç°éŸ³é‡è°ƒæ•´",
                "parameters": {
                    "volume": "integer",
                    "device": "string"
                }
            }
        ]
    }
}


# ============================================================
# æ¨¡æ‹Ÿå·¥å…·æ‰§è¡Œ
# ============================================================

class MockToolExecutor:
    """æ¨¡æ‹Ÿå·¥å…·æ‰§è¡Œå™¨ï¼ˆæ— éœ€çœŸå® D-Busï¼‰"""
    
    def __init__(self):
        self.execution_log = []
    
    def execute(self, tool_name: str, parameters: Dict) -> Dict:
        """æ¨¡æ‹Ÿæ‰§è¡Œå·¥å…·"""
        timestamp = datetime.now().isoformat()
        
        result = {
            "tool_name": tool_name,
            "parameters": parameters,
            "timestamp": timestamp,
            "success": True
        }
        
        # æ¨¡æ‹Ÿä¸åŒå·¥å…·çš„è¿”å›ç»“æœ
        if "search_file" in tool_name:
            result["result"] = {
                "files": [
                    {"file_name": "image1.png", "file_path": "~/Downloads/image1.png"},
                    {"file_name": "image2.png", "file_path": "~/Downloads/image2.png"}
                ],
                "count": 2
            }
            result["message"] = f"æœç´¢å®Œæˆï¼Œæ‰¾åˆ° 2 ä¸ªæ–‡ä»¶"
            
        elif "move_to_trash" in tool_name:
            result["result"] = {"moved": parameters.get("file_path", "")}
            result["message"] = f"æ–‡ä»¶å·²ç§»åŠ¨åˆ°å›æ”¶ç«™"
            
        elif "change_wallpaper" in tool_name:
            result["result"] = {"wallpaper": parameters.get("wallpaper_path", "")}
            result["message"] = f"å£çº¸è®¾ç½®æˆåŠŸ"
            
        elif "adjust_volume" in tool_name:
            result["result"] = {"volume": parameters.get("volume", 50)}
            result["message"] = f"éŸ³é‡å·²è°ƒæ•´åˆ° {parameters.get('volume', 50)}%"
            
        else:
            result["success"] = False
            result["error"] = f"æœªçŸ¥å·¥å…·: {tool_name}"
        
        self.execution_log.append(result)
        return result


# ============================================================
# æ¨ç†é“¾è§£æä¸æ‰§è¡Œ
# ============================================================

def parse_execution_plan(reasoning_chain: Dict) -> List[Dict]:
    """
    ä»æ¨ç†é“¾ä¸­è§£ææ‰§è¡Œè®¡åˆ’
    
    Args:
        reasoning_chain: æ¨ç†é“¾å­—å…¸
        
    Returns:
        æ‰§è¡Œæ­¥éª¤åˆ—è¡¨
    """
    steps = []
    
    execution_plan = reasoning_chain.get("execution_plan", [])
    
    for step in execution_plan:
        action = step.get("action", "")
        agent = step.get("agent", "")
        
        # å°è¯•åŒ¹é…å·¥å…·
        tool_info = match_tool_from_action(action, agent)
        
        steps.append({
            "step": step.get("step", len(steps) + 1),
            "action": action,
            "agent": agent,
            "tool": tool_info
        })
    
    return steps


def match_tool_from_action(action: str, agent: str) -> Optional[Dict]:
    """
    ä»åŠ¨ä½œæè¿°ä¸­åŒ¹é…å·¥å…·
    
    Args:
        action: åŠ¨ä½œæè¿°
        agent: æ™ºèƒ½ä½“åç§°
        
    Returns:
        å·¥å…·ä¿¡æ¯å­—å…¸
    """
    action_lower = action.lower()
    
    # FileAgent å·¥å…·åŒ¹é…
    if agent == "FileAgent" or "æ–‡ä»¶" in action or "æœç´¢" in action:
        if "æœç´¢" in action or "search" in action_lower:
            return {
                "name": "file_agent.search_file",
                "parameters": extract_search_params(action)
            }
        elif "å›æ”¶ç«™" in action or "åˆ é™¤" in action or "ç§»åŠ¨" in action or "trash" in action_lower:
            return {
                "name": "file_agent.move_to_trash",
                "parameters": extract_trash_params(action)
            }
    
    # SettingsAgent å·¥å…·åŒ¹é…
    if agent == "SettingsAgent" or "è®¾ç½®" in action:
        if "å£çº¸" in action or "wallpaper" in action_lower:
            return {
                "name": "settings_agent.change_wallpaper",
                "parameters": extract_wallpaper_params(action)
            }
        elif "éŸ³é‡" in action or "volume" in action_lower:
            return {
                "name": "settings_agent.adjust_volume",
                "parameters": extract_volume_params(action)
            }
    
    return None


def extract_search_params(action: str) -> Dict:
    """ä»åŠ¨ä½œæè¿°ä¸­æå–æœç´¢å‚æ•°"""
    import re
    
    params = {
        "search_path": "~/Downloads",
        "keyword": "*.png",
        "recursive": True
    }
    
    # æå–è·¯å¾„
    path_match = re.search(r'[~/\w]+/\w+', action)
    if path_match:
        params["search_path"] = path_match.group(0)
    
    # æå–æ–‡ä»¶æ¨¡å¼
    pattern_match = re.search(r'\*?\.\w+', action)
    if pattern_match:
        params["keyword"] = pattern_match.group(0)
    
    return params


def extract_trash_params(action: str) -> Dict:
    """ä»åŠ¨ä½œæè¿°ä¸­æå–åˆ é™¤å‚æ•°"""
    import re
    
    params = {"file_path": ""}
    
    path_match = re.search(r'[~/\w]+/[\w.]+', action)
    if path_match:
        params["file_path"] = path_match.group(0)
    
    return params


def extract_wallpaper_params(action: str) -> Dict:
    """ä»åŠ¨ä½œæè¿°ä¸­æå–å£çº¸å‚æ•°"""
    import re
    
    params = {
        "wallpaper_path": "",
        "scale": "zoom"
    }
    
    path_match = re.search(r'[~/\w]+/[\w.]+\.(png|jpg|jpeg)', action, re.IGNORECASE)
    if path_match:
        params["wallpaper_path"] = path_match.group(0)
    
    return params


def extract_volume_params(action: str) -> Dict:
    """ä»åŠ¨ä½œæè¿°ä¸­æå–éŸ³é‡å‚æ•°"""
    import re
    
    params = {
        "volume": 50,
        "device": "@DEFAULT_SINK@"
    }
    
    vol_match = re.search(r'(\d+)\s*%?', action)
    if vol_match:
        params["volume"] = int(vol_match.group(1))
    
    return params


# ============================================================
# å…¨é“¾è·¯æ‰§è¡Œ
# ============================================================

def execute_full_pipeline(
    user_task: str,
    mock_mode: bool = True,
    verbose: bool = True
) -> Dict:
    """
    æ‰§è¡Œå®Œæ•´çš„ GUI Agent æµç¨‹
    
    æµç¨‹ï¼šç”¨æˆ·ä»»åŠ¡ â†’ è®°å¿†æ£€ç´¢ â†’ System-2 æ¨ç† â†’ å·¥å…·æ‰§è¡Œ â†’ ç»“æœå­˜å‚¨
    
    Args:
        user_task: ç”¨æˆ·ä»»åŠ¡æè¿°
        mock_mode: æ˜¯å¦ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼
        verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
        
    Returns:
        æ‰§è¡Œç»“æœå­—å…¸
    """
    result = {
        "task": user_task,
        "timestamp": datetime.now().isoformat(),
        "pipeline_steps": [],
        "success": False
    }
    
    if verbose:
        print("\n" + "=" * 70)
        print("ğŸš€ Kylin-TARS GUI Agent å…¨é“¾è·¯æ‰§è¡Œ")
        print("=" * 70)
        print(f"ğŸ“ ç”¨æˆ·ä»»åŠ¡: {user_task}")
        print(f"ğŸ”§ è¿è¡Œæ¨¡å¼: {'æ¨¡æ‹Ÿæ¨¡å¼' if mock_mode else 'çœŸå®æ¨¡å¼'}")
    
    # Step 1: è®°å¿†æ£€ç´¢
    if verbose:
        print("\n" + "-" * 50)
        print("Step 1: è®°å¿†æ£€ç´¢")
        print("-" * 50)
    
    reused_reasoning = None
    similar_traj = retrieve_similar_trajectory(user_task, threshold=60, verbose=verbose)
    
    if similar_traj:
        reused_reasoning = similar_traj.get("reasoning_chain")
        result["pipeline_steps"].append({
            "step": "memory_retrieval",
            "status": "reused",
            "similar_task": similar_traj.get("task"),
            "similarity": "â‰¥60%"
        })
        if verbose:
            print(f"âœ“ æ‰¾åˆ°ç›¸ä¼¼ä»»åŠ¡ï¼Œå¤ç”¨æ¨ç†é“¾")
    else:
        result["pipeline_steps"].append({
            "step": "memory_retrieval",
            "status": "not_found"
        })
        if verbose:
            print(f"â—‹ æœªæ‰¾åˆ°ç›¸ä¼¼ä»»åŠ¡ï¼Œå°†ç”Ÿæˆæ–°æ¨ç†é“¾")
    
    # Step 2: System-2 æ¨ç†
    if verbose:
        print("\n" + "-" * 50)
        print("Step 2: System-2 æ¨ç†")
        print("-" * 50)
    
    if reused_reasoning:
        reasoning_chain = reused_reasoning
        if verbose:
            print("âœ“ å¤ç”¨å†å²æ¨ç†é“¾")
    else:
        reasoning_chain, _ = reasoning_with_memory(
            user_task=user_task,
            enable_reuse=False,
            verbose=verbose
        )
    
    # éªŒè¯æ¨ç†é“¾æ ¼å¼
    is_valid, msg = validate_for_mcp(reasoning_chain)
    if not is_valid:
        reasoning_chain = normalize_for_mcp(reasoning_chain)
        if verbose:
            print(f"âš ï¸ æ¨ç†é“¾æ ¼å¼æ ‡å‡†åŒ–: {msg}")
    
    result["reasoning_chain"] = reasoning_chain
    result["pipeline_steps"].append({
        "step": "reasoning",
        "status": "success" if reasoning_chain else "failed",
        "reused": bool(reused_reasoning)
    })
    
    # æ‰“å°æ¨ç†é“¾æ‘˜è¦
    if verbose and reasoning_chain:
        tc = reasoning_chain.get("thought_chain", {})
        print(f"\nğŸ“‹ æ¨ç†é“¾æ‘˜è¦:")
        print(f"   ä»»åŠ¡åˆ†è§£: {tc.get('task_decomposition', 'N/A')[:80]}...")
        print(f"   é£é™©è¯„ä¼°: {tc.get('risk_assessment', 'N/A')}")
    
    # Step 3: è§£ææ‰§è¡Œè®¡åˆ’
    if verbose:
        print("\n" + "-" * 50)
        print("Step 3: è§£ææ‰§è¡Œè®¡åˆ’")
        print("-" * 50)
    
    execution_steps = parse_execution_plan(reasoning_chain)
    
    if verbose:
        print(f"ğŸ“Š è§£æå‡º {len(execution_steps)} ä¸ªæ‰§è¡Œæ­¥éª¤:")
        for step in execution_steps:
            tool_name = step["tool"]["name"] if step["tool"] else "æ— å·¥å…·"
            print(f"   {step['step']}. {step['action'][:40]}... â†’ {tool_name}")
    
    # Step 4: æ‰§è¡Œå·¥å…·è°ƒç”¨
    if verbose:
        print("\n" + "-" * 50)
        print("Step 4: æ‰§è¡Œå·¥å…·è°ƒç”¨")
        print("-" * 50)
    
    executor = MockToolExecutor()
    execution_results = []
    
    for step in execution_steps:
        if step["tool"]:
            tool_name = step["tool"]["name"]
            parameters = step["tool"]["parameters"]
            
            if verbose:
                print(f"\n   æ‰§è¡Œ: {tool_name}")
                print(f"   å‚æ•°: {parameters}")
            
            tool_result = executor.execute(tool_name, parameters)
            execution_results.append(tool_result)
            
            if verbose:
                status = "âœ“" if tool_result["success"] else "âœ—"
                print(f"   ç»“æœ: {status} {tool_result.get('message', '')}")
        else:
            if verbose:
                print(f"\n   æ­¥éª¤ {step['step']}: æ— éœ€å·¥å…·è°ƒç”¨ - {step['action'][:40]}...")
    
    result["execution_results"] = execution_results
    result["pipeline_steps"].append({
        "step": "execution",
        "status": "success" if all(r.get("success", False) for r in execution_results) else "partial",
        "tool_calls": len(execution_results)
    })
    
    # Step 5: å­˜å‚¨åä½œè½¨è¿¹
    if verbose:
        print("\n" + "-" * 50)
        print("Step 5: å­˜å‚¨åä½œè½¨è¿¹")
        print("-" * 50)
    
    execution_summary = json.dumps(execution_results, ensure_ascii=False)
    overall_success = all(r.get("success", False) for r in execution_results) if execution_results else True
    
    trajectory_path = save_collaboration_trajectory(
        task=user_task,
        reasoning_chain=reasoning_chain,
        execution_result=execution_summary,
        screenshot_paths=[],
        success=overall_success,
        metadata={
            "source": "full_integration",
            "mock_mode": mock_mode,
            "reused_reasoning": bool(reused_reasoning)
        }
    )
    
    result["trajectory_path"] = trajectory_path
    result["pipeline_steps"].append({
        "step": "storage",
        "status": "success",
        "path": trajectory_path
    })
    
    result["success"] = overall_success
    
    # æ‰“å°æ€»ç»“
    if verbose:
        print("\n" + "=" * 70)
        print("ğŸ“Š æ‰§è¡Œæ€»ç»“")
        print("=" * 70)
        print(f"   ä»»åŠ¡: {user_task[:50]}...")
        print(f"   æ¨ç†é“¾å¤ç”¨: {'æ˜¯' if reused_reasoning else 'å¦'}")
        print(f"   å·¥å…·è°ƒç”¨: {len(execution_results)} æ¬¡")
        print(f"   æ‰§è¡ŒçŠ¶æ€: {'âœ“ æˆåŠŸ' if overall_success else 'âœ— éƒ¨åˆ†å¤±è´¥'}")
        print(f"   è½¨è¿¹å­˜å‚¨: {trajectory_path}")
    
    return result


# ============================================================
# æµ‹è¯•ç”¨ä¾‹
# ============================================================

def test_full_integration():
    """å…¨é“¾è·¯æµ‹è¯•"""
    print("\n" + "ğŸ§ª Kylin-TARS å…¨é“¾è·¯è”è°ƒæµ‹è¯• ğŸ§ª".center(70))
    print("=" * 70)
    
    # æµ‹è¯•ä»»åŠ¡åˆ—è¡¨
    test_tasks = [
        "æœç´¢~/Downloadsç›®å½•çš„pngæ–‡ä»¶å¹¶è®¾ç½®ä¸ºå£çº¸",
        "æŠŠç³»ç»ŸéŸ³é‡è°ƒåˆ°50%",
        "å°†ä¸‹è½½ç›®å½•çš„tmpæ–‡ä»¶ç§»åŠ¨åˆ°å›æ”¶ç«™",
    ]
    
    results = []
    
    for i, task in enumerate(test_tasks, 1):
        print(f"\n\n{'#' * 70}")
        print(f"# æµ‹è¯• {i}/{len(test_tasks)}: {task}")
        print(f"{'#' * 70}")
        
        result = execute_full_pipeline(
            user_task=task,
            mock_mode=True,
            verbose=True
        )
        results.append(result)
        
        # é—´éš”ä»¥ä¾¿è§‚å¯Ÿ
        time.sleep(1)
    
    # æ‰“å°æµ‹è¯•æŠ¥å‘Š
    print("\n\n" + "=" * 70)
    print("ğŸ“‹ æµ‹è¯•æŠ¥å‘Š")
    print("=" * 70)
    
    success_count = sum(1 for r in results if r["success"])
    print(f"æ€»æµ‹è¯•æ•°: {len(results)}")
    print(f"æˆåŠŸæ•°é‡: {success_count}")
    print(f"æˆåŠŸç‡: {success_count/len(results)*100:.1f}%")
    
    print("\nè¯¦ç»†ç»“æœ:")
    for i, r in enumerate(results, 1):
        status = "âœ“" if r["success"] else "âœ—"
        print(f"  {i}. {r['task'][:40]}... {status}")
    
    # æµ‹è¯•è®°å¿†æ£€ç´¢
    print("\n\n" + "=" * 70)
    print("ğŸ“‹ è®°å¿†æ£€ç´¢æµ‹è¯•")
    print("=" * 70)
    
    # ä½¿ç”¨ç›¸ä¼¼ä»»åŠ¡æµ‹è¯•æ£€ç´¢
    similar_task = "æœç´¢ä¸‹è½½ç›®å½•çš„jpgæ–‡ä»¶è®¾ä¸ºå£çº¸"
    print(f"\næµ‹è¯•ä»»åŠ¡: {similar_task}")
    
    result = execute_full_pipeline(
        user_task=similar_task,
        mock_mode=True,
        verbose=True
    )
    
    if result.get("pipeline_steps"):
        retrieval_step = next((s for s in result["pipeline_steps"] if s["step"] == "memory_retrieval"), None)
        if retrieval_step and retrieval_step.get("status") == "reused":
            print("\nâœ“ è®°å¿†æ£€ç´¢æµ‹è¯•é€šè¿‡: æˆåŠŸå¤ç”¨å†å²æ¨ç†é“¾")
        else:
            print("\nâ—‹ è®°å¿†æ£€ç´¢æµ‹è¯•: æœªå¤ç”¨å†å²æ¨ç†é“¾ï¼ˆå¯èƒ½é˜ˆå€¼ä¸è¶³ï¼‰")
    
    print("\n" + "=" * 70)
    print("âœ“ å…¨é“¾è·¯è”è°ƒæµ‹è¯•å®Œæˆ!")
    print("=" * 70)


# ============================================================
# ä¸»å‡½æ•°
# ============================================================

def main():
    parser = argparse.ArgumentParser(description="Kylin-TARS GUI Agent å…¨é“¾è·¯è”è°ƒ")
    parser.add_argument("--real", action="store_true", help="ä½¿ç”¨çœŸå®æ¨¡å¼ï¼ˆéœ€è¦å¯åŠ¨ MCP Serverï¼‰")
    parser.add_argument("--task", type=str, help="æŒ‡å®šæµ‹è¯•ä»»åŠ¡")
    args = parser.parse_args()
    
    if args.task:
        # æ‰§è¡Œå•ä¸ªä»»åŠ¡
        execute_full_pipeline(
            user_task=args.task,
            mock_mode=not args.real,
            verbose=True
        )
    else:
        # è¿è¡Œå®Œæ•´æµ‹è¯•
        test_full_integration()


if __name__ == "__main__":
    main()

